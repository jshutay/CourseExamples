{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Data Science template to explore data and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639606181816
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# You need to run this block of code to import the libraries that are needed for the data manipulations, visualizations, etc. \n",
    "\n",
    "from pydoc import help  # can type in the python console `help(name of function)` to get the documentation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Import your data and start exploring\n",
    "#### Note, the hash or pound sign makes the computer skip that line of code, we also use that sign for comments in a code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639606228222
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Read csv file into pandas dataframe\n",
    "\n",
    "df = pd.read_csv(\"PutYourFileNameHere.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639606281699
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Run this block of code to view the first five rows of data. If you want more rows, then put the number in the parentheses\n",
    "# For example, if you put a 10 in the parentheses, it will give you 10 rows. In Python the first row and column are numbered as zero\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639606370162
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create a function that we can re-use\n",
    "# This block of code will create a histogram. You don't have to use all of this code next time you want to create one\n",
    "def show_distribution(var_data):\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    # Get statistics\n",
    "    min_val = var_data.min()\n",
    "    max_val = var_data.max()\n",
    "    mean_val = var_data.mean()\n",
    "    med_val = var_data.median()\n",
    "    mod_val = var_data.mode()[0]\n",
    "\n",
    "    print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\n",
    "                                                                                            mean_val,\n",
    "                                                                                            med_val,\n",
    "                                                                                            mod_val,\n",
    "                                                                                            max_val))\n",
    "\n",
    "    # Create a figure for 2 subplots (2 rows, 1 column)\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n",
    "\n",
    "    # Plot the histogram   \n",
    "    ax[0].hist(var_data)\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Add lines for the mean, median, and mode\n",
    "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "\n",
    "    # Plot the boxplot   \n",
    "    ax[1].boxplot(var_data, vert=False)\n",
    "    ax[1].set_xlabel('Value')\n",
    "\n",
    "    # Add a title to the Figure\n",
    "    fig.suptitle('Data Distribution')\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# For future histograms, just rerun these lines of code and update the variable name to be the variable you want \n",
    "# If you are using a new dataset with a different name, change df to whatever the name is for your dataset \n",
    "# Get the variable to examine\n",
    "col = df['VarName']\n",
    "# Call the function\n",
    "show_distribution(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1635889558205
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# You only need this part of the code above for new histograms\n",
    "# Get the variable to examine\n",
    "col = df['VarName']\n",
    "# Call the function\n",
    "show_distribution(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1635889800274
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Exploring relationships - this code will create scatter plots \n",
    "# Change Var1, etc. with the actual variable names. You can add more if you want. \n",
    "# If dataset name is something other than df, change df to the dataset name. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "  \n",
    "# selecting numerical features\n",
    "features = ['Var1', 'Var2', 'Var3', 'Var4']\n",
    "   \n",
    "# plotting the scatter matrix\n",
    "# with the features\n",
    "scatter_matrix(df[features], figsize=(12,12))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# If you want to compare groups based on one or more quantitative variables, use this code\n",
    "\n",
    "#In the short_df = df[col_list] line of code, be sure to change df to whatever your dataset name is\n",
    "\n",
    "col_list = ['GroupingVarName', 'Var2', 'Var3', 'Var4', 'Var5', 'Var6']\n",
    "short_df = df[col_list]\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "rs=1999\n",
    " \n",
    "df_long = pd.melt(short_df.sample(1000,random_state=rs), \"GroupingVarName\", var_name=\"Columns\", value_name=\"Values\")   \n",
    "f,ax = plt.subplots(figsize=(16,8))\n",
    "#plt.xticks(rotation=90) - use if you want to rotate the visualization\n",
    "#plt.ylim(0, 10) - use if you want to limit the y axis to a min and/or max value\n",
    "#plt.xlim(0, None) - use if you want to limit the x axis to a min and/or max value\n",
    "sns.boxplot(x=\"Columns\", y=\"Values\", hue=\"GroupingVarName\", data=df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1635890269030
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Removing outliers - Use if you want to get rid of outliers and rerun the matrix\n",
    "# You can add more lines for additional variables\n",
    "# Typically we use 3 standard deviations (e.g., Six Sigma - 3 SDs above and below mean)\n",
    "\n",
    "#Create a new dataset (df2) so that you don't replace the values in df\n",
    "df2=df\n",
    "\n",
    "from scipy import stats\n",
    "df2=df2[(np.abs(stats.zscore(df2['Var1'])) < 3)]\n",
    "df2=df2[(np.abs(stats.zscore(df2['Var2'])) < 3)]\n",
    "df2=df2[(np.abs(stats.zscore(df2['Var3'])) < 3)]\n",
    "df2=df2[(np.abs(stats.zscore(df2['Var4'])) < 3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1636055724700
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Use this if doing normalization - setting the scale to be between 0 and 1\n",
    "# You would only do this if you want to standardize your variables and have all of them on same scale\n",
    "# This would be preferred over creating z scores if your distribution is not normal\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Again, creating a new dataset so we don't replace the values in the original dataset\n",
    "df2=df\n",
    "\n",
    "# Applying scaler() to all the columns except the 'yes-no' and 'dummy' variables\n",
    "num_vars = ['Var1', 'Var2', 'Var3', 'Var4']\n",
    "df2[num_vars] = scaler.fit_transform(df2[num_vars])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Use this if doing standardization (z scores) - you would do this or the one above, but not both\n",
    "# This code creates a z score that has zero as the mean. It is different than normalization\n",
    "\n",
    "df['Var1'] = (df['Var1'] - df['Var1'].mean())/df['Var1'].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1636556361081
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Decomposition model to get seasonality, trend and noise\n",
    "# This code creates a time series with 3 components (seasonal, trend, and noise)\n",
    "# Change Var1 with your variable of interest. Change df to your dataset name if it is different\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result=seasonal_decompose(df['Var1'], model='additive', freq=12, extrapolate_trend=12)\n",
    "\n",
    "\n",
    "result.plot()\n",
    "# pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1636556369148
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Run this code to save the three components so you can download to csv file. \n",
    "\n",
    "df['trend'] = result.trend\n",
    "\n",
    "df['residual'] = result.resid\n",
    "\n",
    "df['seasonal'] = result.seasonal\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1636553225115
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Run this code if you get errors about infinity values or missing values and rerun time series\n",
    "# Note that this can cause you to end up with no values so you may need to try to transform, etc. instead of simply deleting\n",
    "\n",
    "# Replace Inf values with NaN\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "# Drop all occurences of NaN\n",
    "df = df.dropna()\n",
    "# Double check these are all gone\n",
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Use this code to save your dataset to a csv file that will load into this folder\n",
    "\n",
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## This section provides examples for multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1636553362180
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# This is code to run a linear regression analysis\n",
    "# Change df to be your dataset name if it is different\n",
    "# Change Target to be your dependent variable\n",
    "# Change Var1, Var2, Var3, Var4 to be the name of your predictor variables\n",
    "# You can add more predictors if you want\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "\n",
    "new_model = ols(\"\"\"Target ~ Var1 \n",
    "                                     + Var2 \n",
    "                                     + Var3\n",
    "                                     + Var4\"\"\", data=df).fit()\n",
    "# summarize our model\n",
    "new_model_summary = new_model.summary()\n",
    "HTML(new_model_summary.as_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1636556414182
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    " #This code block runs regression diagnostic visualizations (partial plots)\n",
    "\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "fig = sm.graphics.plot_partregress_grid(new_model, fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# This produces our four regression plots for specified feature variable (e.g., one of your predictor variables)\n",
    "# You would run this code for each predictor variable\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "# pass in the model as the first parameter, then specify the \n",
    "# predictor variable we want to analyze\n",
    "fig = sm.graphics.plot_regress_exog(new_model, \"Var1\", fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## This section provides examples for decision trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Creating a list of features for the decision tree\n",
    "# Include in this list, all the predictor variables that you want to use in your decision tree\n",
    "\n",
    "features=['Var1',\n",
    " 'Var2',\n",
    " 'Var3',\n",
    " 'Var4',\n",
    " 'Var5',\n",
    " 'Var6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# This block of code runs the decision tree analysis\n",
    "# Replace TargetVar with the name of the target or dependent variable of interest\n",
    "# max_depth and max_leaf_nodes are hyper parameters that are set by the researcher, they limit the size of the tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn import datasets, tree\n",
    "\n",
    "y = df[\"TargetVar\"]\n",
    "X = df[features].astype(float)\n",
    "dt = DecisionTreeRegressor(min_samples_split=1000, min_samples_leaf=1000, random_state=99, max_depth=5, max_leaf_nodes=7)\n",
    "dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Creating a visual of the tree\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                                feature_names=feature_names,  \n",
    "                                filled=True)\n",
    "graphviz.Source(dot_data, format=\"png\") "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
